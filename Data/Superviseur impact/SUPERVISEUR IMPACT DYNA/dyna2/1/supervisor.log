2020-02-03 12:22:14.457 o.a.s.v.ConfigValidation main [WARN] task.heartbeat.frequency.secs is a deprecated config please see class org.apache.storm.Config.TASK_HEARTBEAT_FREQUENCY_SECS for more information.
2020-02-03 12:22:14.561 o.a.s.v.ConfigValidation main [WARN] task.heartbeat.frequency.secs is a deprecated config please see class org.apache.storm.Config.TASK_HEARTBEAT_FREQUENCY_SECS for more information.
2020-02-03 12:22:14.651 o.a.s.s.o.a.c.u.Compatibility main [INFO] Running in ZooKeeper 3.4.x compatibility mode
2020-02-03 12:22:14.651 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2020-02-03 12:22:14.671 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2020-02-03 12:22:14.671 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2020-02-03 12:22:14.676 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=bb21ef6aa46e
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=1.8.0_242
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Oracle Corporation
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/local/openjdk-8
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/apache-storm-2.1.0/*:/apache-storm-2.1.0/lib/asm-5.0.3.jar:/apache-storm-2.1.0/lib/commons-cli-1.4.jar:/apache-storm-2.1.0/lib/storm-shaded-deps-2.1.0.jar:/apache-storm-2.1.0/lib/jline-0.9.94.jar:/apache-storm-2.1.0/lib/failureaccess-1.0.1.jar:/apache-storm-2.1.0/lib/jetty-servlets-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/jsr305-3.0.2.jar:/apache-storm-2.1.0/lib/commons-io-2.6.jar:/apache-storm-2.1.0/lib/commons-logging-1.2.jar:/apache-storm-2.1.0/lib/accessors-smart-1.2.jar:/apache-storm-2.1.0/lib/nimbus-jose-jwt-4.41.1.jar:/apache-storm-2.1.0/lib/jetty-server-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/httpclient-4.5.6.jar:/apache-storm-2.1.0/lib/curator-framework-4.2.0.jar:/apache-storm-2.1.0/lib/metrics-graphite-3.2.6.jar:/apache-storm-2.1.0/lib/slf4j-api-1.7.26.jar:/apache-storm-2.1.0/lib/minlog-1.3.0.jar:/apache-storm-2.1.0/lib/carbonite-1.5.0.jar:/apache-storm-2.1.0/lib/error_prone_annotations-2.2.0.jar:/apache-storm-2.1.0/lib/log4j-over-slf4j-1.7.26.jar:/apache-storm-2.1.0/lib/json-simple-1.1.jar:/apache-storm-2.1.0/lib/core.specs.alpha-0.2.44.jar:/apache-storm-2.1.0/lib/rocksdbjni-5.18.3.jar:/apache-storm-2.1.0/lib/storm-core-2.1.0.jar:/apache-storm-2.1.0/lib/chill-java-0.8.0.jar:/apache-storm-2.1.0/lib/tools.logging-0.2.3.jar:/apache-storm-2.1.0/lib/netty-3.10.6.Final.jar:/apache-storm-2.1.0/lib/hadoop-auth-2.8.5.jar:/apache-storm-2.1.0/lib/jetty-servlet-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/apache-storm-2.1.0/lib/storm-server-2.1.0.jar:/apache-storm-2.1.0/lib/curator-client-4.2.0.jar:/apache-storm-2.1.0/lib/httpcore-4.4.10.jar:/apache-storm-2.1.0/lib/commons-lang-2.6.jar:/apache-storm-2.1.0/lib/jetty-continuation-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/log4j-slf4j-impl-2.11.2.jar:/apache-storm-2.1.0/lib/commons-exec-1.3.jar:/apache-storm-2.1.0/lib/joda-time-2.3.jar:/apache-storm-2.1.0/lib/guava-27.0.1-jre.jar:/apache-storm-2.1.0/lib/jetty-io-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/log4j-api-2.11.2.jar:/apache-storm-2.1.0/lib/jetty-util-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/log4j-core-2.11.2.jar:/apache-storm-2.1.0/lib/clojure-1.10.0.jar:/apache-storm-2.1.0/lib/kryo-shaded-3.0.3.jar:/apache-storm-2.1.0/lib/storm-client-2.1.0.jar:/apache-storm-2.1.0/lib/json-smart-2.3.jar:/apache-storm-2.1.0/lib/j2objc-annotations-1.1.jar:/apache-storm-2.1.0/lib/audience-annotations-0.5.0.jar:/apache-storm-2.1.0/lib/javax.servlet-api-3.1.0.jar:/apache-storm-2.1.0/lib/metrics-core-3.2.6.jar:/apache-storm-2.1.0/lib/storm-clojure-2.1.0.jar:/apache-storm-2.1.0/lib/reflectasm-1.10.1.jar:/apache-storm-2.1.0/lib/jaxb-api-2.3.0.jar:/apache-storm-2.1.0/lib/checker-qual-2.5.2.jar:/apache-storm-2.1.0/lib/commons-collections-3.2.2.jar:/apache-storm-2.1.0/lib/commons-fileupload-1.3.3.jar:/apache-storm-2.1.0/lib/javax.annotation-api-1.3.2.jar:/apache-storm-2.1.0/lib/kryo-3.0.3.jar:/apache-storm-2.1.0/lib/jackson-core-2.9.8.jar:/apache-storm-2.1.0/lib/snakeyaml-1.11.jar:/apache-storm-2.1.0/lib/objenesis-2.1.jar:/apache-storm-2.1.0/lib/jetty-security-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/spec.alpha-0.2.176.jar:/apache-storm-2.1.0/lib/zookeeper-3.4.14.jar:/apache-storm-2.1.0/lib/jetty-http-9.4.14.v20181114.jar:/apache-storm-2.1.0/lib/commons-compress-1.18.jar:/apache-storm-2.1.0/lib/jackson-dataformat-smile-2.9.8.jar:/apache-storm-2.1.0/lib/commons-codec-1.11.jar:/apache-storm-2.1.0/lib/animal-sniffer-annotations-1.17.jar:/apache-storm-2.1.0/lib/jcip-annotations-1.0-1.jar:/apache-storm-2.1.0/extlib/*:/apache-storm-2.1.0/extlib-daemon/*:/conf
2020-02-03 12:22:14.677 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2020-02-03 12:22:14.678 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp
2020-02-03 12:22:14.678 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2020-02-03 12:22:14.678 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2020-02-03 12:22:14.678 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2020-02-03 12:22:14.678 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=5.3.0-28-generic
2020-02-03 12:22:14.680 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=storm
2020-02-03 12:22:14.680 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/home/storm
2020-02-03 12:22:14.680 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/apache-storm-2.1.0
2020-02-03 12:22:14.681 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@75cd8043
2020-02-03 12:22:14.743 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2020-02-03 12:22:14.744 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Opening socket connection to server zookeeper/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2020-02-03 12:22:14.749 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Socket connection established to zookeeper/172.18.0.3:2181, initiating session
2020-02-03 12:22:14.753 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Session establishment complete on server zookeeper/172.18.0.3:2181, sessionid = 0x1000051bd090030, negotiated timeout = 20000
2020-02-03 12:22:14.758 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2020-02-03 12:22:14.761 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2020-02-03 12:22:14.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x1000051bd090030 closed
2020-02-03 12:22:14.763 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000051bd090030
2020-02-03 12:22:14.764 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2020-02-03 12:22:14.764 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2020-02-03 12:22:14.765 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@61ce23ac
2020-02-03 12:22:14.765 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Opening socket connection to server zookeeper/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2020-02-03 12:22:14.766 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Socket connection established to zookeeper/172.18.0.3:2181, initiating session
2020-02-03 12:22:14.767 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2020-02-03 12:22:14.767 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper:2181) [INFO] Session establishment complete on server zookeeper/172.18.0.3:2181, sessionid = 0x1000051bd090031, negotiated timeout = 20000
2020-02-03 12:22:14.767 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2020-02-03 12:22:14.780 o.a.s.l.AsyncLocalizer main [INFO] Reconstruct localized resources
2020-02-03 12:22:14.786 o.a.s.d.s.Supervisor main [INFO] Starting supervisor for storm version '2.1.0'.
2020-02-03 12:22:14.790 o.a.s.d.s.Supervisor main [INFO] Starting Supervisor with conf {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupMemory=org.apache.storm.metric.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metric.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metric.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metric.cgroup.CGroupCpuGuarantee}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[zookeeper], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/data, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.worker.shared.thread.pool.size=4, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[nimbus], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=*****, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=1, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=true, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, storm.log.dir=/logs, topology.spout.recvq.skips=3, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2020-02-03 12:22:14.858 o.a.s.d.s.Slot main [INFO] SLOT bb21ef6aa46e:6700 Starting in state empty - assignment null
2020-02-03 12:22:14.859 o.a.s.d.s.Slot main [INFO] SLOT bb21ef6aa46e:6701 Starting in state empty - assignment null
2020-02-03 12:22:14.859 o.a.s.d.s.Slot main [INFO] SLOT bb21ef6aa46e:6702 Starting in state empty - assignment null
2020-02-03 12:22:14.859 o.a.s.d.s.Slot main [INFO] SLOT bb21ef6aa46e:6703 Starting in state empty - assignment null
2020-02-03 12:22:14.866 o.a.s.d.s.Supervisor main [INFO] Starting supervisor with id fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4 at host bb21ef6aa46e.
2020-02-03 12:22:14.869 o.a.s.d.m.ClientMetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
2020-02-03 12:22:14.870 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...
2020-02-03 12:22:14.877 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...
2020-02-03 12:22:15.813 o.a.s.u.NimbusClient timer [INFO] Found leader nimbus : 90341ec5fc1f:6627
2020-02-03 12:22:44.865 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:22:44.866 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:22:47.228 o.a.s.d.s.Supervisor pool-10-thread-1 [INFO] Got an assignments from master, will start to sync with assignments: SupervisorAssignments(storm_assignment:{WordCountTopo-4-1580732557=Assignment(master_code_dir:/data, node_host:{50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5=fcbc6770b893, c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6=76afdafb42ad, fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4=bb21ef6aa46e}, executor_node_port:{[14, 14]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [28, 28]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [30, 30]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [26, 26]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [10, 10]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [8, 8]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [12, 12]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [24, 24]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [20, 20]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [22, 22]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [16, 16]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [18, 18]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [6, 6]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [2, 2]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [4, 4]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [19, 19]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [15, 15]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [17, 17]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [13, 13]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [11, 11]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [7, 7]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [9, 9]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [23, 23]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [25, 25]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [29, 29]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [31, 31]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [27, 27]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [21, 21]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [5, 5]=NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700]), [1, 1]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [3, 3]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700])}, executor_start_time_secs:{[8, 8]=1580732567, [4, 4]=1580732567, [10, 10]=1580732567, [12, 12]=1580732567, [14, 14]=1580732567, [2, 2]=1580732567, [16, 16]=1580732567, [22, 22]=1580732567, [24, 24]=1580732567, [26, 26]=1580732567, [18, 18]=1580732567, [20, 20]=1580732567, [28, 28]=1580732567, [30, 30]=1580732567, [6, 6]=1580732567, [19, 19]=1580732567, [7, 7]=1580732567, [1, 1]=1580732567, [3, 3]=1580732567, [5, 5]=1580732567, [13, 13]=1580732567, [15, 15]=1580732567, [17, 17]=1580732567, [9, 9]=1580732567, [11, 11]=1580732567, [25, 25]=1580732567, [21, 21]=1580732567, [23, 23]=1580732567, [31, 31]=1580732567, [29, 29]=1580732567, [27, 27]=1580732567}, worker_resources:{NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700])=WorkerResources(mem_on_heap:1408.0, mem_off_heap:0.0, cpu:110.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1408.0, cpu.pcore.percent=110.0}, shared_resources:{}), NodeInfo(node:c49c128c-2869-449c-8326-e9cb27244ad6-172.18.0.6, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:storm)})
2020-02-03 12:22:47.880 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE empty msInState: 33022 -> waiting-for-blob-localization msInState: 0
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 4 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormconf.ser.version
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 1 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormcode.ser.version
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar.version
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 4 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormconf.ser
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 1 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormcode.ser
2020-02-03 12:22:48.881 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/resources
2020-02-03 12:22:48.958 o.a.s.d.s.Slot SLOT_6700 [INFO] There are pending changes, waiting for them to finish before launching container...
2020-02-03 12:22:48.959 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-localization msInState: 1079 -> waiting-for-blob-update msInState: 0
2020-02-03 12:22:48.959 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Assignment Changed from null to LocalAssignment(topology_id:WordCountTopo-4-1580732557, executors:[ExecutorInfo(task_start:24, task_end:24), ExecutorInfo(task_start:30, task_end:30), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:18, task_end:18), ExecutorInfo(task_start:21, task_end:21), ExecutorInfo(task_start:15, task_end:15), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:9, task_end:9), ExecutorInfo(task_start:27, task_end:27)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm)
2020-02-03 12:22:48.963 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-update msInState: 4 -> waiting-for-blob-localization msInState: 0
2020-02-03 12:22:48.974 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Created Worker ID 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:22:48.975 o.a.s.d.s.Container SLOT_6700 [INFO] Setting up fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:22:48.975 o.a.s.d.s.Container SLOT_6700 [INFO] GET worker-user for 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:22:49.043 o.a.s.d.s.Container SLOT_6700 [INFO] SET worker-user 9165a590-4998-401d-bee6-b004327f1acb storm
2020-02-03 12:22:49.044 o.a.s.d.s.Container SLOT_6700 [INFO] Creating symlinks for worker-id: 9165a590-4998-401d-bee6-b004327f1acb storm-id: WordCountTopo-4-1580732557 for files(1): [resources]
2020-02-03 12:22:49.044 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Launching worker with assignment LocalAssignment(topology_id:WordCountTopo-4-1580732557, executors:[ExecutorInfo(task_start:24, task_end:24), ExecutorInfo(task_start:30, task_end:30), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:18, task_end:18), ExecutorInfo(task_start:21, task_end:21), ExecutorInfo(task_start:15, task_end:15), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:9, task_end:9), ExecutorInfo(task_start:27, task_end:27)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) for this supervisor fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4 on port 6700 with id 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:22:49.069 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Launching worker with command: '/usr/local/openjdk-8/bin/java' '-cp' '/apache-storm-2.1.0/lib-worker/*:/apache-storm-2.1.0/extlib/*:/conf:/data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar' '-Xmx64m' '-Dlogging.sensitivity=S3' '-Dlogfile.name=worker.log' '-Dstorm.home=/apache-storm-2.1.0' '-Dworkers.artifacts=/logs/workers-artifacts' '-Dstorm.id=WordCountTopo-4-1580732557' '-Dworker.id=9165a590-4998-401d-bee6-b004327f1acb' '-Dworker.port=6700' '-Dstorm.log.dir=/logs' '-DLog4jContextSelector=org.apache.logging.log4j.core.selector.BasicContextSelector' '-Dstorm.local.dir=/data' '-Dworker.memory_limit_mb=1280' '-Dlog4j.configurationFile=/apache-storm-2.1.0/log4j2/worker.xml' 'org.apache.storm.LogWriter' '/usr/local/openjdk-8/bin/java' '-server' '-Dlogging.sensitivity=S3' '-Dlogfile.name=worker.log' '-Dstorm.home=/apache-storm-2.1.0' '-Dworkers.artifacts=/logs/workers-artifacts' '-Dstorm.id=WordCountTopo-4-1580732557' '-Dworker.id=9165a590-4998-401d-bee6-b004327f1acb' '-Dworker.port=6700' '-Dstorm.log.dir=/logs' '-DLog4jContextSelector=org.apache.logging.log4j.core.selector.BasicContextSelector' '-Dstorm.local.dir=/data' '-Dworker.memory_limit_mb=1280' '-Dlog4j.configurationFile=/apache-storm-2.1.0/log4j2/worker.xml' '-Xmx1280m' '-XX:+PrintGCDetails' '-Xloggc:artifacts/gc.log' '-XX:+PrintGCDateStamps' '-XX:+PrintGCTimeStamps' '-XX:+UseGCLogFileRotation' '-XX:NumberOfGCLogFiles=10' '-XX:GCLogFileSize=1M' '-XX:+HeapDumpOnOutOfMemoryError' '-XX:HeapDumpPath=artifacts/heapdump' '-Djava.library.path=/data/supervisor/stormdist/WordCountTopo-4-1580732557/resources/Linux-amd64:/data/supervisor/stormdist/WordCountTopo-4-1580732557/resources:/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64' '-Dstorm.conf.file=' '-Dstorm.options=' '-Djava.io.tmpdir=/data/workers/9165a590-4998-401d-bee6-b004327f1acb/tmp' '-cp' '/apache-storm-2.1.0/lib-worker/*:/apache-storm-2.1.0/extlib/*:/conf:/data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar' 'org.apache.storm.daemon.worker.Worker' 'WordCountTopo-4-1580732557' 'fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4' '6628' '6700' '9165a590-4998-401d-bee6-b004327f1acb'. 
2020-02-03 12:22:49.073 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-localization msInState: 110 -> waiting-for-worker-start msInState: 0 topo:WordCountTopo-4-1580732557 worker:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:22:49.073 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Changing current assignment from null to LocalAssignment(topology_id:WordCountTopo-4-1580732557, executors:[ExecutorInfo(task_start:24, task_end:24), ExecutorInfo(task_start:30, task_end:30), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:18, task_end:18), ExecutorInfo(task_start:21, task_end:21), ExecutorInfo(task_start:15, task_end:15), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:9, task_end:9), ExecutorInfo(task_start:27, task_end:27)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm)
2020-02-03 12:22:52.077 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-worker-start msInState: 3005 topo:WordCountTopo-4-1580732557 worker:9165a590-4998-401d-bee6-b004327f1acb -> running msInState: 1 topo:WordCountTopo-4-1580732557 worker:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:23:14.945 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:23:14.946 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:23:44.947 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:23:44.948 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:24:14.953 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:24:14.953 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:24:44.953 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:24:44.953 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:25:14.957 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:25:14.957 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:25:44.957 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:25:44.957 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:26:15.038 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:26:15.038 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:26:45.038 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:26:45.038 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:27:15.041 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:27:15.041 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:27:45.043 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:27:45.043 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:28:15.044 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:28:15.044 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:28:45.046 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:28:45.046 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:29:15.047 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:29:15.047 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:29:45.049 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:29:45.050 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:30:15.050 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:30:15.050 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:30:45.057 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:30:45.057 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:31:15.057 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:31:15.058 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:31:45.058 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:31:45.058 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:32:15.061 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:32:15.061 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:32:45.138 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:32:45.138 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:33:15.141 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:33:15.142 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:33:45.145 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:33:45.145 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:34:15.149 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:34:15.149 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:34:38.738 o.a.s.d.s.Supervisor pool-10-thread-5 [INFO] Got an assignments from master, will start to sync with assignments: SupervisorAssignments(storm_assignment:{})
2020-02-03 12:34:39.262 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Assignment Changed from LocalAssignment(topology_id:WordCountTopo-4-1580732557, executors:[ExecutorInfo(task_start:24, task_end:24), ExecutorInfo(task_start:30, task_end:30), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:18, task_end:18), ExecutorInfo(task_start:21, task_end:21), ExecutorInfo(task_start:15, task_end:15), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:9, task_end:9), ExecutorInfo(task_start:27, task_end:27)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) to null
2020-02-03 12:34:39.353 o.a.s.d.s.Container SLOT_6700 [INFO] Killing fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.091 o.a.s.d.s.BasicContainer Thread-10 [INFO] Worker Process 9165a590-4998-401d-bee6-b004327f1acb exited with code: 143
2020-02-03 12:34:42.743 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE running msInState: 710666 topo:WordCountTopo-4-1580732557 worker:9165a590-4998-401d-bee6-b004327f1acb -> kill msInState: 3001 topo:WordCountTopo-4-1580732557 worker:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.745 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700 all processes are dead...
2020-02-03 12:34:42.746 o.a.s.d.s.Container SLOT_6700 [INFO] Cleaning up fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.746 o.a.s.d.s.Container SLOT_6700 [INFO] GET worker-user for 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.747 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/9165a590-4998-401d-bee6-b004327f1acb/pids/121
2020-02-03 12:34:42.747 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/9165a590-4998-401d-bee6-b004327f1acb/heartbeats
2020-02-03 12:34:42.751 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/9165a590-4998-401d-bee6-b004327f1acb/pids
2020-02-03 12:34:42.751 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/9165a590-4998-401d-bee6-b004327f1acb/tmp
2020-02-03 12:34:42.752 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.752 o.a.s.d.s.Container SLOT_6700 [INFO] REMOVE worker-user 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.752 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers-users/9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.753 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Removed Worker ID 9165a590-4998-401d-bee6-b004327f1acb
2020-02-03 12:34:42.754 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE kill msInState: 3012 topo:WordCountTopo-4-1580732557 worker:null -> empty msInState: 0
2020-02-03 12:34:42.754 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Changing current assignment from LocalAssignment(topology_id:WordCountTopo-4-1580732557, executors:[ExecutorInfo(task_start:24, task_end:24), ExecutorInfo(task_start:30, task_end:30), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:18, task_end:18), ExecutorInfo(task_start:21, task_end:21), ExecutorInfo(task_start:15, task_end:15), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:9, task_end:9), ExecutorInfo(task_start:27, task_end:27)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) to null
2020-02-03 12:34:45.149 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:34:45.149 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:35:15.150 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:35:15.150 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:35:45.151 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:35:45.152 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:36:15.152 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:36:15.153 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:36:44.873 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar
2020-02-03 12:36:44.873 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormjar.jar.version
2020-02-03 12:36:44.873 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/resources
2020-02-03 12:36:44.874 o.a.s.l.LocalizedResourceRetentionSet AsyncLocalizer Executor - 0 [INFO] Deleted blob: WordCountTopo-4-1580732557-stormjar.jar (REMOVED FROM CLUSTER).
2020-02-03 12:36:44.879 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormcode.ser.version
2020-02-03 12:36:44.879 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormcode.ser
2020-02-03 12:36:44.879 o.a.s.l.LocalizedResourceRetentionSet AsyncLocalizer Executor - 0 [INFO] Deleted blob: WordCountTopo-4-1580732557-stormcode.ser (REMOVED FROM CLUSTER).
2020-02-03 12:36:44.884 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormconf.ser
2020-02-03 12:36:44.884 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557/stormconf.ser.version
2020-02-03 12:36:44.884 o.a.s.l.LocalizedResourceRetentionSet AsyncLocalizer Executor - 0 [INFO] Deleted blob: WordCountTopo-4-1580732557-stormconf.ser (REMOVED FROM CLUSTER).
2020-02-03 12:36:44.885 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-4-1580732557
2020-02-03 12:36:45.154 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:36:45.154 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:37:15.154 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:37:15.155 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:37:45.156 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:37:45.157 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:38:15.158 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:38:15.158 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:38:45.159 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:38:45.159 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:39:15.161 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:39:15.161 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:39:45.161 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:39:45.162 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:40:15.162 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:40:15.162 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:40:45.162 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:40:45.163 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:41:15.163 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:41:15.163 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:41:45.164 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:41:45.164 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:42:15.164 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:42:15.164 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:42:45.165 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:42:45.165 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:43:15.166 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:43:15.166 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:43:45.167 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:43:45.167 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:44:15.167 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:44:15.168 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:44:45.168 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:44:45.169 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:45:15.170 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:45:15.170 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:45:45.172 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:45:45.172 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:46:15.173 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:46:15.173 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:46:45.173 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:46:45.174 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:46:48.381 o.a.s.d.s.Supervisor pool-10-thread-7 [INFO] Got an assignments from master, will start to sync with assignments: SupervisorAssignments(storm_assignment:{WordCountTopo-5-1580734006=Assignment(master_code_dir:/data, node_host:{50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5=fcbc6770b893, fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4=bb21ef6aa46e}, executor_node_port:{[10, 10]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [14, 14]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [16, 16]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [12, 12]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [8, 8]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [6, 6]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [4, 4]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [2, 2]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [20, 20]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [18, 18]=NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700]), [15, 15]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [7, 7]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [5, 5]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [21, 21]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [3, 3]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [19, 19]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [1, 1]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [17, 17]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [13, 13]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [11, 11]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700]), [9, 9]=NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700])}, executor_start_time_secs:{[8, 8]=1580734008, [2, 2]=1580734008, [4, 4]=1580734008, [6, 6]=1580734008, [10, 10]=1580734008, [12, 12]=1580734008, [14, 14]=1580734008, [16, 16]=1580734008, [18, 18]=1580734008, [20, 20]=1580734008, [7, 7]=1580734008, [1, 1]=1580734008, [3, 3]=1580734008, [5, 5]=1580734008, [9, 9]=1580734008, [11, 11]=1580734008, [13, 13]=1580734008, [15, 15]=1580734008, [17, 17]=1580734008, [19, 19]=1580734008, [21, 21]=1580734008}, worker_resources:{NodeInfo(node:50250312-bf07-4336-9e87-926fc0e55caf-172.18.0.5, port:[6700])=WorkerResources(mem_on_heap:1408.0, mem_off_heap:0.0, cpu:110.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1408.0, cpu.pcore.percent=110.0}, shared_resources:{}), NodeInfo(node:fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:storm)})
2020-02-03 12:46:49.054 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE empty msInState: 726301 -> waiting-for-blob-localization msInState: 1
2020-02-03 12:46:50.055 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormjar.jar.version
2020-02-03 12:46:50.055 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormconf.ser.version
2020-02-03 12:46:50.055 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 3 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormcode.ser.version
2020-02-03 12:46:50.056 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 3 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormcode.ser
2020-02-03 12:46:50.056 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 0 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormconf.ser
2020-02-03 12:46:50.056 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/stormjar.jar
2020-02-03 12:46:50.056 o.a.s.d.s.AdvancedFSOps AsyncLocalizer Executor - 2 [INFO] Deleting path /data/supervisor/stormdist/WordCountTopo-5-1580734006/resources
2020-02-03 12:46:50.058 o.a.s.d.s.Slot SLOT_6700 [INFO] There are pending changes, waiting for them to finish before launching container...
2020-02-03 12:46:50.058 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-localization msInState: 1004 -> waiting-for-blob-update msInState: 0
2020-02-03 12:46:50.058 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Assignment Changed from null to LocalAssignment(topology_id:WordCountTopo-5-1580734006, executors:[ExecutorInfo(task_start:10, task_end:10), ExecutorInfo(task_start:14, task_end:14), ExecutorInfo(task_start:16, task_end:16), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:20, task_end:20), ExecutorInfo(task_start:18, task_end:18)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm)
2020-02-03 12:46:50.059 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-update msInState: 1 -> waiting-for-blob-localization msInState: 0
2020-02-03 12:46:50.061 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Created Worker ID 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:46:50.061 o.a.s.d.s.Container SLOT_6700 [INFO] Setting up fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:46:50.062 o.a.s.d.s.Container SLOT_6700 [INFO] GET worker-user for 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:46:50.062 o.a.s.d.s.Container SLOT_6700 [INFO] SET worker-user 1939e588-0ff0-4b62-bb35-5e77a4afb04a storm
2020-02-03 12:46:50.063 o.a.s.d.s.Container SLOT_6700 [INFO] Creating symlinks for worker-id: 1939e588-0ff0-4b62-bb35-5e77a4afb04a storm-id: WordCountTopo-5-1580734006 for files(1): [resources]
2020-02-03 12:46:50.063 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Launching worker with assignment LocalAssignment(topology_id:WordCountTopo-5-1580734006, executors:[ExecutorInfo(task_start:10, task_end:10), ExecutorInfo(task_start:14, task_end:14), ExecutorInfo(task_start:16, task_end:16), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:20, task_end:20), ExecutorInfo(task_start:18, task_end:18)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) for this supervisor fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4 on port 6700 with id 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:46:50.064 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Launching worker with command: '/usr/local/openjdk-8/bin/java' '-cp' '/apache-storm-2.1.0/lib-worker/*:/apache-storm-2.1.0/extlib/*:/conf:/data/supervisor/stormdist/WordCountTopo-5-1580734006/stormjar.jar' '-Xmx64m' '-Dlogging.sensitivity=S3' '-Dlogfile.name=worker.log' '-Dstorm.home=/apache-storm-2.1.0' '-Dworkers.artifacts=/logs/workers-artifacts' '-Dstorm.id=WordCountTopo-5-1580734006' '-Dworker.id=1939e588-0ff0-4b62-bb35-5e77a4afb04a' '-Dworker.port=6700' '-Dstorm.log.dir=/logs' '-DLog4jContextSelector=org.apache.logging.log4j.core.selector.BasicContextSelector' '-Dstorm.local.dir=/data' '-Dworker.memory_limit_mb=1280' '-Dlog4j.configurationFile=/apache-storm-2.1.0/log4j2/worker.xml' 'org.apache.storm.LogWriter' '/usr/local/openjdk-8/bin/java' '-server' '-Dlogging.sensitivity=S3' '-Dlogfile.name=worker.log' '-Dstorm.home=/apache-storm-2.1.0' '-Dworkers.artifacts=/logs/workers-artifacts' '-Dstorm.id=WordCountTopo-5-1580734006' '-Dworker.id=1939e588-0ff0-4b62-bb35-5e77a4afb04a' '-Dworker.port=6700' '-Dstorm.log.dir=/logs' '-DLog4jContextSelector=org.apache.logging.log4j.core.selector.BasicContextSelector' '-Dstorm.local.dir=/data' '-Dworker.memory_limit_mb=1280' '-Dlog4j.configurationFile=/apache-storm-2.1.0/log4j2/worker.xml' '-Xmx1280m' '-XX:+PrintGCDetails' '-Xloggc:artifacts/gc.log' '-XX:+PrintGCDateStamps' '-XX:+PrintGCTimeStamps' '-XX:+UseGCLogFileRotation' '-XX:NumberOfGCLogFiles=10' '-XX:GCLogFileSize=1M' '-XX:+HeapDumpOnOutOfMemoryError' '-XX:HeapDumpPath=artifacts/heapdump' '-Djava.library.path=/data/supervisor/stormdist/WordCountTopo-5-1580734006/resources/Linux-amd64:/data/supervisor/stormdist/WordCountTopo-5-1580734006/resources:/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64' '-Dstorm.conf.file=' '-Dstorm.options=' '-Djava.io.tmpdir=/data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a/tmp' '-cp' '/apache-storm-2.1.0/lib-worker/*:/apache-storm-2.1.0/extlib/*:/conf:/data/supervisor/stormdist/WordCountTopo-5-1580734006/stormjar.jar' 'org.apache.storm.daemon.worker.Worker' 'WordCountTopo-5-1580734006' 'fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4' '6628' '6700' '1939e588-0ff0-4b62-bb35-5e77a4afb04a'. 
2020-02-03 12:46:50.065 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-blob-localization msInState: 6 -> waiting-for-worker-start msInState: 1 topo:WordCountTopo-5-1580734006 worker:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:46:50.065 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Changing current assignment from null to LocalAssignment(topology_id:WordCountTopo-5-1580734006, executors:[ExecutorInfo(task_start:10, task_end:10), ExecutorInfo(task_start:14, task_end:14), ExecutorInfo(task_start:16, task_end:16), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:20, task_end:20), ExecutorInfo(task_start:18, task_end:18)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm)
2020-02-03 12:46:53.139 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE waiting-for-worker-start msInState: 3075 topo:WordCountTopo-5-1580734006 worker:1939e588-0ff0-4b62-bb35-5e77a4afb04a -> running msInState: 0 topo:WordCountTopo-5-1580734006 worker:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:47:15.174 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:47:15.174 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:47:45.174 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:47:45.174 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:48:15.175 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:48:15.175 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:48:45.175 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:48:45.175 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:49:15.175 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:49:15.176 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:49:45.176 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:49:45.176 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:50:15.238 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:50:15.238 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:50:45.241 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:50:45.241 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:51:15.241 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:51:15.241 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:51:45.243 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:51:45.244 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:52:15.244 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:52:15.244 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:52:45.244 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:52:45.244 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:53:15.245 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:53:15.245 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:53:45.245 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:53:45.245 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:54:15.245 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:54:15.246 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:54:45.246 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:54:45.246 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:55:15.250 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:55:15.252 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:55:45.252 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:55:45.253 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:56:15.253 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:56:15.253 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:56:45.253 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:56:45.253 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:57:15.253 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:57:15.254 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:57:45.254 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:57:45.254 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:58:15.255 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:58:15.255 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:58:45.255 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:58:45.255 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:58:47.438 o.a.s.d.s.Supervisor pool-10-thread-1 [INFO] Got an assignments from master, will start to sync with assignments: SupervisorAssignments(storm_assignment:{})
2020-02-03 12:58:49.254 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Assignment Changed from LocalAssignment(topology_id:WordCountTopo-5-1580734006, executors:[ExecutorInfo(task_start:10, task_end:10), ExecutorInfo(task_start:14, task_end:14), ExecutorInfo(task_start:16, task_end:16), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:20, task_end:20), ExecutorInfo(task_start:18, task_end:18)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) to null
2020-02-03 12:58:49.346 o.a.s.d.s.Container SLOT_6700 [INFO] Killing fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:51.780 o.a.s.d.s.BasicContainer Thread-13 [INFO] Worker Process 1939e588-0ff0-4b62-bb35-5e77a4afb04a exited with code: 143
2020-02-03 12:58:52.446 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE running msInState: 719307 topo:WordCountTopo-5-1580734006 worker:1939e588-0ff0-4b62-bb35-5e77a4afb04a -> kill msInState: 3001 topo:WordCountTopo-5-1580734006 worker:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.449 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700 all processes are dead...
2020-02-03 12:58:52.449 o.a.s.d.s.Container SLOT_6700 [INFO] Cleaning up fa1396d9-7b51-4ca0-9255-ad4fe094b760-172.18.0.4:1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.449 o.a.s.d.s.Container SLOT_6700 [INFO] GET worker-user for 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.450 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a/pids/221
2020-02-03 12:58:52.450 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a/heartbeats
2020-02-03 12:58:52.455 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a/pids
2020-02-03 12:58:52.455 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a/tmp
2020-02-03 12:58:52.455 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers/1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.455 o.a.s.d.s.Container SLOT_6700 [INFO] REMOVE worker-user 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.455 o.a.s.d.s.AdvancedFSOps SLOT_6700 [INFO] Deleting path /data/workers-users/1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.456 o.a.s.d.s.BasicContainer SLOT_6700 [INFO] Removed Worker ID 1939e588-0ff0-4b62-bb35-5e77a4afb04a
2020-02-03 12:58:52.457 o.a.s.d.s.Slot SLOT_6700 [INFO] STATE kill msInState: 3013 topo:WordCountTopo-5-1580734006 worker:null -> empty msInState: 1
2020-02-03 12:58:52.458 o.a.s.d.s.Slot SLOT_6700 [INFO] SLOT 6700: Changing current assignment from LocalAssignment(topology_id:WordCountTopo-5-1580734006, executors:[ExecutorInfo(task_start:10, task_end:10), ExecutorInfo(task_start:14, task_end:14), ExecutorInfo(task_start:16, task_end:16), ExecutorInfo(task_start:12, task_end:12), ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:20, task_end:20), ExecutorInfo(task_start:18, task_end:18)], resources:WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{offheap.memory.mb=0.0, onheap.memory.mb=1280.0, cpu.pcore.percent=100.0}, shared_resources:{}), owner:storm) to null
2020-02-03 12:59:15.256 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:59:15.256 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
2020-02-03 12:59:45.257 o.a.s.d.s.t.SupervisorHealthCheck timer [INFO] Running supervisor healthchecks...
2020-02-03 12:59:45.257 o.a.s.h.HealthChecker timer [INFO] The supervisor healthchecks succeeded.
